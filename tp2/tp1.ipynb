{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Trabajo Practico N2</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Primer Punto</h1>\n",
    "<h2>Levantando los datos</h2>\n",
    "\n",
    "<blockquote>\n",
    "    <p> Los datasets los transformamos a formato .hdf para acelerar la entrada. El script utilizado para realizar la transformación se encuentra en el siguiente link: <a href=\"https://drive.google.com/file/d/0B31LWRR8593HM095d04tamFKRWs/view?usp=sharing\">https://drive.google.com/file/d/0B31LWRR8593HM095d04tamFKRWs/view?usp=sharing</a>. Generamos dos vectores de DataFrames, uno por cada grupo de personas:\n",
    "    <ul>\n",
    "        <li>Personas con capacidades cognitivas severamente disminuidas (<i>pacientes_P</i>)</li>\n",
    "        <li>Personas con capacidad cognitiva normal (<i>pacientes_S</i>)</li>\n",
    "    </ul>\n",
    "    \n",
    "    <p> Sólo trabajaremos con los electrodos en el conjunto {8,44,80,131,185}\n",
    "    \n",
    "    \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"datos\"\n",
    "load_path = path + \"/{}.hdf\"\n",
    "electrodos = [8, 44, 80, 131, 185]\n",
    "\n",
    "N_P = 10\n",
    "N_S = 10\n",
    "pacientes_P = []\n",
    "pacientes_S = []\n",
    "for load_name, N, dest, offset in [(\"P\", N_P, pacientes_P, 0), (\"S\", N_S, pacientes_S, 10)]:\n",
    "    for i in range(1, 1 + N):\n",
    "        paciente = load_name + \"{:02d}\".format(i)\n",
    "        df_ = pd.read_hdf(load_path.format(paciente))\n",
    "        df_ = df_.loc[offset + i-1,:,electrodos,:]\n",
    "        dest.append(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Primera vista de los datos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<p>La información quedó cargada como multi-índice.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pacientes_S[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_primer_plot = np.array(pacientes_S[0].loc[10,0,8,:])\n",
    "sns.plt.plot(range(len(df_primer_plot)),df_primer_plot, color=\"orange\", label=\"fasdfsadf\")\n",
    "sns.plt.ylabel('Voltage', fontsize=17)\n",
    "sns.plt.xlabel('Muestras \"equiespaciadas\"', fontsize=17)\n",
    "sns.plt.title('Electrodo 8 en la persona 10 en un intervalo de 1.54 segundos', fontsize=20)\n",
    "## Podriamos marcar el estimulo: sns.plt.axvline(x=25, color='grey', linestyle='--')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ejercicio 1 - Análisis de Frecuencias</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <p>Nuestros datos de entrada presentan 201 muestras por cada Paciente-Sensor-Epoch con frecuencia de 250 Hz. \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 1 - A</h3>\n",
    "<blockquote>\n",
    "    <p>Potencia de las Frecuencias para cada Epoch de cada Paciente.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Me quedo con los sensores [8,44,80,131,185] de cada paciente\n",
    "dfs1 = [pacientes_P[i].loc[i,:,[8,44,80,131,185],:] for i in range(N_P)] + \\\n",
    "    [pacientes_S[i].loc[i + 10,:,[8,44,80,131,185],:] for i in range(N_S)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Para cada paciente, promedio los voltages de todos los sensores \n",
    "#   agrupando por epoch y tiempo .\n",
    "sensor_means = [df.groupby(['epoch', 'tiempo']).mean() for df in dfs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indice_persona = 1\n",
    "esta_persona_tiene_capacidad_cognitiva_disminuida = True\n",
    "capacidad_cognitiva = \"P\"#\"capacidad cognitiva disminuida\"\n",
    "\n",
    "def copy_data_rounded_by_two_decimals(algunosValoresConMuchosDecimales):\n",
    "    valoresRedondeados = []\n",
    "    for i in range(len(algunosValoresConMuchosDecimales)):\n",
    "        valoresRedondeados.append(round(algunosValoresConMuchosDecimales[i],2))\n",
    "    return valoresRedondeados\n",
    "\n",
    "def graficar_heatmap_potencia_frencuencia_por_epoch_para_los_datos_de_esta_persona(datos,persona, capacidad_cognitiva):\n",
    "    frecuencias = sm.groupby(['epoch']).apply(lambda x: scipy.signal.welch(x['valores'], fs=250, nperseg = 201))\n",
    "    data = {' {}'.format(i): f for i,f in enumerate(map(lambda x: x[1], frecuencias.values))}\n",
    "    index = copy_index_rounded_by_two_decimals(frecuencias.values[0][0])\n",
    "    f_df = pd.DataFrame(data=data, index=index)\n",
    "    \n",
    "    g = sns.heatmap(f_df, xticklabels=175, yticklabels=10, robust=True)\n",
    "    \n",
    "        \n",
    "    sns.plt.title('Paciente {} ({})'.format(persona, capacidad_cognitiva), fontsize=20, y=1.08)\n",
    "    sns.plt.ylabel('Frecuencia (Hz)', fontsize=14)\n",
    "    sns.plt.xlabel('Epochs', fontsize=14)\n",
    "    ## Descomentar esto para reducir el rango de Frecuencias de 0 a 50 como en el enunciado\n",
    "    # axes = sns.plt.gca()\n",
    "    # axes.set_ylim([60,101])\n",
    "    sns.plt.show()\n",
    "\n",
    "## Descomentar para poder ver todos\n",
    "#\n",
    "#for sm in sensor_means:\n",
    "#    \n",
    "#    if indice_persona > 10 and esta_persona_tiene_capacidad_cognitiva_disminuida:\n",
    "#        esta_persona_tiene_capacidad_cognitiva_disminuida = False\n",
    "#        indice_persona = 1\n",
    "#        capacidad_cognitiva = \"S\"#\"capacidad cognitiva normal\"\n",
    "#    \n",
    "#    graficar_heatmap_potencia_frencuencia_por_epoch_para_los_datos_de_esta_persona(sm,indice_persona,capacidad_cognitiva)\n",
    "#    \n",
    "#    indice_persona+=1\n",
    "    \n",
    "## Dejo uno de muestra\n",
    "graficar_heatmap_potencia_frencuencia_por_epoch_para_los_datos_de_esta_persona(sensor_means[15],6,\"S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 1 - A Bis</h3>\n",
    "<blockquote>\n",
    "    <p>Calcular la potencia media (entre epochs) para cada frecuencia y graficar la potencia en funcion de la frecuencia para cada canal.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para cada paciente con capacidad cognitiva reducida,\n",
    "#  promedio los voltages agrupando por sensor y tiempo .\n",
    "epoch_means = [df.groupby(['sensor', 'tiempo']).mean() for df in pacientes_P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def graficar_potencia_media_para_cada_frecuencia_en_func_de_la_frecuencia(datos,persona):\n",
    "    for sensor, df_g in datos.groupby(['sensor']):\n",
    "        f, P = scipy.signal.welch(df_g['valores'].values, fs=250, nperseg=201)\n",
    "        sns.plt.plot(f, P)#, xtitle=\"sensor {}\".format(sensor))\n",
    "    axes = sns.plt.gca()\n",
    "    axes.set_xlim([0,50])\n",
    "    sns.plt.title('Paciente {} (P)'.format(persona), fontsize=20, y=1.08)\n",
    "    sns.plt.ylabel('V^2 / Hz', fontsize=14)\n",
    "    sns.plt.xlabel('Frecuencia (Hz)', fontsize=14)\n",
    "\n",
    "    sns.plt.show()\n",
    "\n",
    "    \n",
    "## Descomentar Para graficar todos\n",
    "# \n",
    "#indice_persona = 1\n",
    "#for em in epoch_means:\n",
    "#    graficar_potencia_media_para_cada_frecuencia_en_func_de_la_frecuencia(em, indice_persona)\n",
    "#    indice_persona+=1\n",
    "\n",
    "## Dejamos uno solo de muestra\n",
    "graficar_potencia_media_para_cada_frecuencia_en_func_de_la_frecuencia(epoch_means[7], 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 1 - B</h3>\n",
    "<blockquote>\n",
    "    <p>Calcular los valores de cada banda de frecuencia, promediados entre los electrodos (todos) y epochs para cada paciente.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_frecuencias(f, P):\n",
    "    return {\n",
    "        'delta': P[f<4].sum(),\n",
    "        'theta': P[(4<=f) & (f<8)].sum(),\n",
    "        'alpha': P[(8<=f) & (f<13)].sum(),\n",
    "        'beta': P[(13<=f) & (f<30)].sum(),\n",
    "        'gamma': P[30<=f].sum()\n",
    "    }\n",
    "    \n",
    "\n",
    "bandas_P = []\n",
    "bandas_S = []\n",
    "for bandas, pacientes in [(bandas_P, pacientes_P), (bandas_S, pacientes_S)]:\n",
    "    for i, p in enumerate(pacientes):\n",
    "        frecuencia_media = p.groupby(['tiempo']).mean()\n",
    "        f, P = scipy.signal.welch(frecuencia_media['valores'], fs=250, nperseg=201)\n",
    "        bandas.append(calcular_frecuencias(f,P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paciente Con Capacidad Cognitiva Normal 1\n",
    "bandas_S[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 1 - C</h3>\n",
    "<blockquote>\n",
    "    <p>Tomar la potencia de cada sujeto en la banda Alpha y graficar cada uno de los graficos categóricos de seaborn.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_bandas = pd.DataFrame({\n",
    "    \"Capacidad cognitiva\": ([\"Normal\"] * N_S) + ([\"Reducida\"] * N_P),\n",
    "    \"Banda delta\": [d['delta'] for d in bandas_S + bandas_P],\n",
    "    \"Banda theta\": [d['theta'] for d in bandas_S + bandas_P],\n",
    "    \"Banda alpha\": [d['alpha'] for d in bandas_S + bandas_P],\n",
    "    \"Banda beta\": [d['beta'] for d in bandas_S + bandas_P],\n",
    "    \"Banda gamma\": [d['gamma'] for d in bandas_S + bandas_P],\n",
    "})\n",
    "\n",
    "ymin = min(df_bandas['Banda alpha'])\n",
    "ymax = max(df_bandas['Banda alpha'])\n",
    "decimo = (ymax - ymin)/len(df_bandas['Banda alpha'])\n",
    "ymin, ymax = ymin - decimo, ymax + decimo\n",
    "\n",
    "ax = sns.stripplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_ylim([ymin, ymax])\n",
    "ax.set_title(\"Strip plot\", fontsize=16)\n",
    "#sns.plt.title('Paciente {} (P)'.format(indice_persona), fontsize=20, y=1.08)\n",
    "sns.plt.show()\n",
    "\n",
    "ax = sns.swarmplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_ylim([ymin, ymax])\n",
    "ax.set_title(\"Swarm plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n",
    "sns.boxplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_title(\"Box plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n",
    "sns.violinplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_title(\"Violin plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n",
    "sns.lvplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_title(\"Lette value plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n",
    "sns.pointplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_title(\"Point plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n",
    "sns.barplot(x=\"Capacidad cognitiva\", y=\"Banda alpha\", data=df_bandas, palette=\"Set2\")\n",
    "ax.set_title(\"Bar plot\", fontsize=16)\n",
    "sns.plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<p>Los plots <b>violinplot</b> y <b>swarmplot</b> parecen ser los más apropiados para visualizar las diferencias: el primero permite entender la distribución de los elementos, mientras que con el segundo se ven los valores puntuales. Por esta razón se utlizarán estos tipos de gráficos de ahora en más\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ejercicio 1 - D</h3>\n",
    "<blockquote>\n",
    "    <p>Realizamos una comparación de las potencias de cada banda de frecuencia promediando los pacientes por capacidad cognitiva utilizando <b>Violin</b> y <b>Swarm</b>.</p>\n",
    "    </br>\n",
    "    <p>Planteamos un <i>Test de Permutación</i>\n",
    "    <ul>\n",
    "    <li><b>Hipótesis nula:</b> Los pacientes con Capacidades Cognitivas Normales (S) tienen igual o mayor potencia en la banda Delta que los pacientes con Capacidades Cognitivas Severamente Disminuidas.</li>\n",
    "    <li><b>α-level:</b> 0.05</li>\n",
    "    </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcular_delta(d,e):\n",
    "    mean_1_inicial = d[e == e[0]].mean()\n",
    "    mean_2_inicial = d[e != e[0]].mean()\n",
    "    return mean_2_inicial - mean_1_inicial\n",
    "\n",
    "\n",
    "def permutation_test(d,e, n=100):\n",
    "    d0 = calcular_delta(d, e)\n",
    "    deltas = np.zeros(n)\n",
    "    aux_e = e.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "        np.random.shuffle(aux_e)\n",
    "        deltas[i] = calcular_delta(d,aux_e)\n",
    "\n",
    "    return deltas, d0\n",
    "\n",
    "def foo(a, e_a, b, e_b):\n",
    "    e_1 = np.full(a.shape[0], e_a) \n",
    "    e_2 = np.full(b.shape[0], e_b)\n",
    "    e = np.concatenate((e_1, e_2)) \n",
    "    d = np.concatenate((a,b))\n",
    "    return d,e\n",
    "\n",
    "def test_permutacion(cap_cog_reducida, cap_cog_normal ):\n",
    "    d, e = foo(cap_cog_reducida, 'r', cap_cog_normal, 'n')\n",
    "\n",
    "    # delta-value : la diferencia entre las medias que presenta nuestra información \n",
    "    # p-value es la probabilidad de haber obtenido este delta o mayor\n",
    "\n",
    "    deltas, delta_value = permutation_test(d,e)\n",
    "    p_value = deltas[deltas >= delta_value].shape[0]/deltas.shape[0]\n",
    "    \n",
    "    print(\"Delta-value = {} | p-value = {}\".format(delta_value, p_value))\n",
    "    \n",
    "    return p_value\n",
    "    \n",
    "def realizar_test_no_parametrico_con_este_dataframe(df_b):\n",
    "    p_values = {}\n",
    "    for banda in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]:\n",
    "        print(\"\\t- Para la banda {}:\".format(banda))\n",
    "        p_values[banda] = \\\n",
    "            test_permutacion(df_b[(df_b['Banda'] == banda) & (df_b['Capacidad cognitiva'] == \"Reducida\")]['Potencia'],\n",
    "                             df_b[(df_b['Banda'] == banda) & (df_b['Capacidad cognitiva'] == \"Normal\")]['Potencia'])\n",
    "        print(\"\\n\")\n",
    "    \n",
    "def analisis_comparativo(df_b):\n",
    "    ymin = min(df_b['Potencia'])\n",
    "    ymax = max(df_b['Potencia'])\n",
    "    decimo = (ymax - ymin)/len(df_b['Potencia'])\n",
    "    ymin, ymax = ymin - decimo, ymax + decimo\n",
    "\n",
    "    # Hay que tener en cuenta que son pocos valores\n",
    "\n",
    "    ax = sns.violinplot(x=\"Banda\", y=\"Potencia\", hue=\"Capacidad cognitiva\", data=df_b,  split=True, palette=\"Set2\", inner=\"stick\", cut=0)\n",
    "    sns.plt.show()\n",
    "\n",
    "    ax = sns.swarmplot(x=\"Banda\", y=\"Potencia\", hue=\"Capacidad cognitiva\", data=df_b,  split=True, palette=\"Set2\")\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    sns.plt.show()\n",
    "\n",
    "    sns.barplot(x=\"Banda\", y=\"Potencia\", hue=\"Capacidad cognitiva\", data=df_b, palette=\"Set2\")\n",
    "    ax = sns.swarmplot(x=\"Banda\", y=\"Potencia\", hue=\"Capacidad cognitiva\", split=True, data=df_b, palette=\"Set2\")\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    l = ax.legend(handles[:2], labels[:2])\n",
    "    l.set_title(\"Capacidad cognitiva\", prop = {'size':'small'})\n",
    "    sns.plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_bandas = pd.DataFrame({\n",
    "    \"Capacidad cognitiva\": ([\"Reducida\"] * (N_P * 5)) + ([\"Normal\"] * (N_S * 5)),\n",
    "    \"Banda\": list(itertools.chain(*[list(d.keys()) for d in bandas_P + bandas_S])),\n",
    "    \"Potencia\": list(itertools.chain(*[list(d.values()) for d in bandas_P + bandas_S]))\n",
    "})\n",
    "df_bandas_normalizadas = df_bandas.groupby(['Banda']).apply(normalizar_banda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analisis_comparativo(df_bandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <p><b>Planteamos un <i>Test de Permutación</i>:</b>\n",
    "    Nos interesa ver ver como se comportan las potencias de los pacientes con diferentes capacidades cognitivas.\n",
    "    <ul>\n",
    "    <li><b>Hipótesis nula:</b> Los pacientes con capacidades cognitivas normales (S) tienen igual o mayor potencia en la banda X que los pacientes con capacidades cognitivas reducidas (P). Con X alguna de nuestras bandas.</li>\n",
    "    <li><b>α-level:</b> 0.05</li>\n",
    "    </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realizar_test_no_parametrico_con_este_dataframe(df_bandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <p>Hay información suficiente para rechazar <b>H0</b> en todos los casos salvo el de la banda delta.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <p><b>Normalizando:</b> Ahora normalizamos los datos, realizamos una comparación con los mismos plots y volvemos a hacer el test.\n",
    "    \n",
    "    <p><b>Planteamos un <i>Test de Permutación</i>:</b>\n",
    "    Nos interesa ver ver como se comportan las potencias de los pacientes con diferentes capacidades cognitivas.\n",
    "    <ul>\n",
    "    <li><b>Hipótesis nula:</b> Los pacientes con capacidades cognitivas normales (S) tienen igual o mayor potencia en la banda X que los pacientes con capacidades cognitivas reducidas (P). Con X alguna de nuestras bandas.</li>\n",
    "    <li><b>α-level:</b> 0.05</li>\n",
    "    </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizar_banda(df_):\n",
    "    min_pot = min(df_['Potencia'])\n",
    "    max_pot = max(df_['Potencia'])\n",
    "    \n",
    "    df_[\"Potencia\"] = (df_[\"Potencia\"] - min_pot) / (max_pot - min_pot)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"------------\", \"Análisis comparativo normalizado para las distintas bandas:\", sep=\"\\n\")\n",
    "analisis_comparativo(df_bandas_normalizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realizar_test_no_parametrico_con_este_dataframe(df_bandas_normalizadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "    <p>Al igual que antes, hay información suficiente para rechazar <b>H0</b> en los casos de las bandas gamma y beta, pero no hay suficiente información para hacer lo mismo en las demás.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Segundo Punto</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"datos/\"\n",
    "load_path = path + \"{}.hdf\"\n",
    "\n",
    "electrodos = [8, 44, 80, 131, 185]\n",
    "\n",
    "N_P = 10\n",
    "N_S = 10\n",
    "pacientes_P = []\n",
    "pacientes_S = []\n",
    "for load_name, N, dest, offset in [(\"P\", N_P, pacientes_P, 0), (\"S\", N_S, pacientes_S, 10)]:\n",
    "    for i in range(1, 1 + N):\n",
    "        paciente = load_name + \"{:02d}\".format(i)\n",
    "        df_ = pd.read_hdf(load_path.format(paciente))\n",
    "        df_ = df_.loc[offset + i-1,:,electrodos,:]\n",
    "        dest.append(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Análisis intra-electrodo</h1>\n",
    "<h2>Discretizando el espacio de señales</h2>\n",
    "<p>\n",
    "Para poder aplicar alguno de los análisis propuestos en el enunciado es necesario discretizar el espacio de señales aplicando una transformación simbólica.\n",
    "Para esto debe definirse una serie de rangos a los cuales asociaremos las distintas medidas de señales que tenemos.\n",
    "Luego, se asocia a cada rango un símbolo de un alfabeto.\n",
    "<p> La primer dificultad que surge es <b>cómo definir tal alfabeto</b>.\n",
    "Inicialmente se trató de utilizar un único alfabeto para todos los electrodos por igual, tomando los valores máximos y mínimos de todos los datos, pero por la diferencia entre dichos valores la mayoría de las muestras caían en los mismos símbolos.\n",
    "La siguiente figura ejemplifica el problema:\n",
    "\n",
    "<img src=\"bins.png\">\n",
    "\n",
    "La solución a este problema fue tomar un alfabeto por cada electrodo con valores promediados. \n",
    "Se modela como fuente de información cada tupla (paciente, electrodo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculo de N (cantidad de bins): Se usa n = 201 porque los epochs tienen esa cantidad de muestras\n",
    "def calculo_N(df_):\n",
    "    return math.ceil((df_.max() - df_.min()) / (3.5*df_.std() * 201 ** (-1/3)))\n",
    "\n",
    "pacientes = pd.concat(pacientes_P + pacientes_S)\n",
    "val = pacientes.groupby([\"sensor\",\"epoch\"])['valores'].mean()\n",
    "i_s = pd.DataFrame({'sensor':electrodos})\n",
    "i_s['N'] = val.groupby([\"sensor\"]).apply(calculo_N).values\n",
    "i_s['min'] = val.groupby([\"sensor\"]).min().values\n",
    "i_s['max'] = val.groupby([\"sensor\"]).max().values\n",
    "i_s['step'] = (i_s['max'] - i_s['min']) / i_s['N']\n",
    "i_s = i_s.set_index('sensor')\n",
    "i_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente gráfico muestra las divisiones que se realizarían con esta nueva definición de alfabeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pacientes.loc[1,0,8,:]['valores'].plot()\n",
    "for i in range(int(i_s.loc[8]['N'])):\n",
    "    sns.plt.plot((0,200),(i_s.loc[8]['min'] + i*i_s.loc[8]['step'],i_s.loc[8]['min'] + i*i_s.loc[8]['step']),\n",
    "                 'k-', lw = 0.4)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obtener_simbolo(v):\n",
    "    sensor = v.reset_index().sensor[0]\n",
    "    simbolo = (v - i_s.loc[sensor]['min']) // i_s.loc[sensor]['step']\n",
    "    return simbolo\n",
    "pacientes['simbolo'] = pacientes.groupby(\"sensor\").apply(obtener_simbolo).valueso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Análisis de entropía</h2>\n",
    "<p>\n",
    "Una vez realizada la transformación simbólica ya es posible aplicar distitnas métricas para analizar cada uno de los electrodos.\n",
    "En esta primera sección se decidió utilizar la entropía de cada electrodo para cada paciente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculo de probabilidad de cada símbolo. Cada paciente y sensor se considera una fuente de información distinta\n",
    "pacientes['repeticiones'] = pacientes.groupby([\"paciente\", \"sensor\",\"simbolo\"]).transform('count')['valores']\n",
    "pacientes['total'] = pacientes.groupby([\"paciente\", \"sensor\"]).transform('count')['valores']\n",
    "pacientes['probabilidad'] = pacientes['repeticiones'] / pacientes['total']\n",
    "pacientes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_entropia(df_):\n",
    "    df_ = df_.groupby(\"simbolo\").first()\n",
    "    p = df_[\"probabilidad\"]\n",
    "    return -sum(p * np.log(p))\n",
    "\n",
    "entropias_a = pacientes.groupby([\"paciente\",\"sensor\"]).apply(calcular_entropia).reset_index()\n",
    "entropias_a = entropias_a.rename(columns = {0:'Entropia', 'sensor': 'Sensor'})\n",
    "entropias_a['Capacidad Cognitiva'] = (entropias_a.paciente < 10).apply(lambda x: 'Normal' if x else 'Reducida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las siguientes distribuciones de entropía para cada tipo de paciente y para cada uno de los electrodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Sensor\", y=\"Entropia\", hue=\"Capacidad Cognitiva\", data=entropias_a, \n",
    "               split=True, palette=\"Set2\", inner=\"stick\", cut=0)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destaca de inmediato como las distribuciones varían notablemente según el tipo de paciente.\n",
    "Para verificar esto se plantea el siguiente test estadístico para cada electrodo, cuya hipótesis nula <b>HO</b> es que ambos grupos tienen la misma media de entropía y cuyo valor <b>alpha</b> es 0,05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluo la media de información por sensor comparando los individuos con capacidad cognitiva reducida y normal\n",
    "# Uso rank sum con hipótesis nula: \"Ambas muestras tienen la misma media\"\n",
    "\n",
    "for s in electrodos:\n",
    "    x = entropias_a[(entropias_a.Sensor == s) & (entropias_a['Capacidad Cognitiva'] == 'Reducida')].Entropia\n",
    "    y = entropias_a[(entropias_a.Sensor == s) & (entropias_a['Capacidad Cognitiva'] != 'Reducida')].Entropia\n",
    "    _, p = scipy.stats.ranksums(x,y)\n",
    "    print('p-valor misma media para sensor {}: {}'.format(s,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los resultados de los tests se puede afirmar que hay distintas medias para los cinco electrodos en cuestión salvo el número 80.\n",
    "Esto es evidencia de como ambos grupos difieren respecto del nivel de activación de los electrodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Análisis inter-electrodo</h1>\n",
    "<h2>Definición del alfabeto</h2>\n",
    "<p>\n",
    "A diferencia del caso anterior, para realizar este análisis es necesario que todos los electrodos compartan el mismo alfabeto pues si no no serían comparables.\n",
    "Las fuentes de información son cada uno de los electrodos promediados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_P = pd.concat(pacientes_P)\n",
    "df_SP = df_P.groupby([\"sensor\",\"tiempo\"]).mean()\n",
    "df_S = pd.concat(pacientes_S)\n",
    "df_SS = df_S.groupby([\"sensor\", \"tiempo\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcular N para hacer la transformación simbólica\n",
    "pacientes_b_mean = pd.concat(pacientes_P + pacientes_S).groupby([\"sensor\",\"tiempo\"]).mean()\n",
    "N_b = math.ceil(pacientes_b_mean.max() - pacientes_b_mean.min() / (pacientes_b_mean.std() * len(pacientes_b_mean) ** (-1/3)))\n",
    "step_b = (pacientes_b_mean.max() - pacientes_b_mean.min()) / N_b\n",
    "\n",
    "print(N_b, step_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente gráfico ilustra una división en símbolos para este análisis. \n",
    "Para simplificar la transformación simbólica a aquellas valores de intensidad que estén por arriba del límite superior les será asociado el último símbolo.\n",
    "La idea análoga se aplica a aquellos que quedan por debajo del límite inferior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Las lineas indican la separacion en símbolos\n",
    "start_b = pacientes_b_mean.min()\n",
    "\n",
    "fig, ax = sns.plt.subplots(1,1) \n",
    "df_SS.reset_index().groupby(\"sensor\").plot(x=\"tiempo\", y=\"valores\", ax=ax)\n",
    "sns.plt.legend([v[0] for v in df_SS.groupby('sensor')])\n",
    "for i in range(N_b):\n",
    "    sns.plt.plot((0,200),(start_b + i*step_b,start_b + i*step_b), 'k-', lw = 0.4)\n",
    "\n",
    "sns.plt.show()\n",
    "\n",
    "fig, ax = sns.plt.subplots(1,1) \n",
    "df_SP.reset_index().groupby(\"sensor\").plot(x=\"tiempo\", y=\"valores\", ax=ax)\n",
    "sns.plt.legend([v[0] for v in df_SP.groupby('sensor')])\n",
    "for i in range(N_b):\n",
    "    sns.plt.plot((0,200),(start_b + i*step_b,start_b + i*step_b), 'k-', lw = 0.4)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Asigno simbolos de acuerdo al valor\n",
    "def obtener_simbolo_b(v):\n",
    "    return (v - pacientes_b_mean.min()) // step_b\n",
    "df_SS['simbolo'] = df_SS['valores'].apply(obtener_simbolo_b)\n",
    "df_SP['simbolo'] = df_SP['valores'].apply(obtener_simbolo_b)\n",
    "\n",
    "df_SP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_SP['repeticiones'] = df_SP.groupby([\"sensor\",\"simbolo\"]).transform('count')['valores']\n",
    "df_SP['total'] = df_SP.groupby([\"sensor\"]).transform('count')['valores']\n",
    "df_SP['probabilidad'] = df_SP['repeticiones'] / df_SP['total']\n",
    "df_SS['repeticiones'] = df_SS.groupby([\"sensor\",\"simbolo\"]).transform('count')['valores']\n",
    "df_SS['total'] = df_SS.groupby([\"sensor\"]).transform('count')['valores']\n",
    "df_SS['probabilidad'] = df_SS['repeticiones'] / df_SS['total']\n",
    "\n",
    "df_SS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizada la transformación símbolica, se decidió utilizar jointplots para comparar la relación entre las distintas variables que son los símbolos asociados a cada electrodo y a cada paciente.\n",
    "<p>\n",
    "Realizaremos dos tipos de comparaciones:\n",
    "<ol>\n",
    "    <li>Comparación entre individuos de distintos grupos</li>\n",
    "    <li>Comparación entre individuos de mismos grupos</li>\n",
    "</ol>\n",
    "<p> Al realizar estas dos comparaciones se espera poder mostrar como la división de los individuos en estos dos grupos es significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparación entre individuos de distintas capacidad cognitiva</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Comparación de sensores entre personas con capacidad disminuida y normal\n",
    "for e in electrodos:\n",
    "    sensorX = df_SS.loc[e]['simbolo']\n",
    "    sensorY = df_SP.loc[e]['simbolo']\n",
    "    sns.jointplot(sensorX, sensorY, kind='hex', gridsize=30).set_axis_labels(\n",
    "        \"Simbolos capacidad normal sensor {}\".format(e), \"Simbolos capacidad disminuida sensor {}\".format(e))\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparación entre individuos de capacidad cogintiva normal</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comparación de sensores distintos de personas con capacidad cognitiva normal\n",
    "for i, e1 in enumerate(electrodos):\n",
    "    for e2 in electrodos[i+1:]:\n",
    "        sensorX = df_SS.loc[e1]['simbolo']\n",
    "        sensorY = df_SS.loc[e2]['simbolo']\n",
    "        sns.jointplot(sensorX, sensorY, kind='hex', gridsize=30).set_axis_labels(\n",
    "            \"Simbolos sensor {}\".format(e1), \"Simbolos sensor {}\".format(e2))\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del primer grupo de comparaciones se puede concluir que efectivamente las activaciones entre ambos grupos difieren. Con esta comparación se analizan las intensidades para el mismo electrodo pero distintos grupos. Se puede ver que las señales no están fuertemente corelacionadas (en particular el coeficiente de pearson está entre 0.3 y 0.5).\n",
    "<p>\n",
    "Por otro lado, si realizamos comparaciones entre las señales del mismo grupo (como es el caso del segundo grupo de comparaciones) podemos ver como las señales sí están fuertemente corelacionadas (coeficiente de pearson entre 0.97 y 1).\n",
    "<p>\n",
    "Estos dos resultados nos permiten concluir que ambos grupos son caracterizables según la activación de señal de los electrodos propuestos, lo que podría ser un punto de partida para establecer un algoritmo que permita identificar a cual de los dos grupos pertenece un nuevo individuo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
